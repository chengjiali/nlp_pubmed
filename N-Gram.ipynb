{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_size):\n",
    "        super(NGramLM, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(context_size * embedding_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, vocab_size),\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embed = self.embed(inputs)      # [batch_size, context_size, embedding_dim]\n",
    "        embed = embed.view((1, -1))     # [batch_size, context_size * embedding_dim]\n",
    "        logits = self.fnn(embed)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'forty']\n",
      "tensor([20,  4])\n"
     ]
    }
   ],
   "source": [
    "for context, target in trigrams:\n",
    "    print(context)\n",
    "    print(torch.tensor([word_to_ix[w] for w in context], dtype=torch.long))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "CONTEXT_SIZE = 2\n",
    "NEPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NGramLM(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_type = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    tensor_type = torch.cuda.LongTensor\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.17, time_per_iter=0.00\n",
      "Epoch    2: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.13, time_per_iter=0.00\n",
      "Epoch    3: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.13, time_per_iter=0.00\n",
      "Epoch    4: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.13, time_per_iter=0.00\n",
      "Epoch    5: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.12, time_per_iter=0.00\n",
      "Epoch    6: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.13, time_per_iter=0.00\n",
      "Epoch    7: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.13, time_per_iter=0.00\n",
      "Epoch    8: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.13, time_per_iter=0.00\n",
      "Epoch    9: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.12, time_per_iter=0.00\n",
      "Epoch   10: train_loss=521.8302, ppl=216.9555, time_per_epoch=0.13, time_per_iter=0.00\n"
     ]
    }
   ],
   "source": [
    "for EPOCH in range(NEPOCH):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    for context, target in trigrams:\n",
    "        \n",
    "        # Word to index and to tensor\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context]).type(tensor_type)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        log_probs = model(context_idxs)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]]).type(tensor_type))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        i += 1\n",
    "        \n",
    "#         if (sent_id+1) % 1000 == 0:\n",
    "#             print(f'Finished sentences, ({len(train)/(time.time()-start):.2f} words per second)')\n",
    "    print(f'Epoch {EPOCH+1:4}:', \n",
    "          f'train_loss={train_loss:.4f},',\n",
    "          f'ppl={math.exp(train_loss/len(vocab)):.4f},',\n",
    "          f'time_per_epoch={(time.time()-start):.2f},',\n",
    "          f'time_per_iter={(time.time()-start)/i:.2f}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_word2vec_train_example(sent, context_size=2, pad_token=0):\n",
    "    '''\n",
    "    Generate Word2Vec training example, i.e. left + right context -> target.\n",
    "    [0, 0, w_2, w_3] -> w_1, ... [w_n-2, w_n-1, 0, 0] -> w_n\n",
    "    '''\n",
    "    \n",
    "    # Pad the sentence with <S> token\n",
    "    padded_sent = [pad_token] * context_size + sent + [pad_token] * context_size\n",
    "\n",
    "    # Generate training examples\n",
    "    for i in range(context_size, len(sent) + context_size):\n",
    "        context = padded_sent[i - N:i] + padded_sent[i + 1:i + N + 1]\n",
    "        target = [padded_sent[i]]\n",
    "        \n",
    "        yield context, target\n",
    "\n",
    "def gen_lm_train_example(sent, context_size=2, pad_token=0):\n",
    "    '''\n",
    "    Generate LM training example, i.e. context -> target.\n",
    "    [0, 0] -> w_1, ... [w_n-1, w_n] -> 0\n",
    "    '''\n",
    "    \n",
    "    # Pad the sentence with [S] token\n",
    "    padded_sent = sent + [pad_token]\n",
    "\n",
    "    # Generate training examples\n",
    "    context = [pad_token] * context_size\n",
    "    for target in padded_sent:\n",
    "        yield context, target\n",
    "        context = context[1:] + [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class BoW(torch.nn.Module):\n",
    "    '''Bag of Words.\n",
    "    '''\n",
    "    def __init__(self, nwords, ntags):\n",
    "        super(BoW, self).__init__()\n",
    "\n",
    "        tensor_type = torch.FloatTensor\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        if use_cuda:\n",
    "            tensor_type = torch.cuda.FloatTensor\n",
    "\n",
    "        self.bias = Variable(torch.zeros(ntags), requires_grad=True).type(tensor_type)\n",
    "        self.embedding = nn.Embedding(nwords, ntags)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "\n",
    "    def forward(self, words):\n",
    "        emb = self.embedding(words)\n",
    "        out = torch.sum(emb, dim=0) + self.bias # size(out) = N\n",
    "        out = out.view(1, -1) # size(out) = 1 x N\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logger(args):\n",
    "    '''\n",
    "    Write logs to checkpoint and console\n",
    "    '''\n",
    "\n",
    "    if args.train:\n",
    "        log_file = os.path.join(args.save_path or args.init_checkpoint, 'train.log')\n",
    "    else:\n",
    "        log_file = os.path.join(args.save_path or args.init_checkpoint, 'test.log')\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        filename=log_file,\n",
    "        filemode='w'\n",
    "    )\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    \n",
    "    model = Model()\n",
    "\n",
    "    logging.info('Model Parameter:')\n",
    "    for name, param in kge_model.named_parameters():\n",
    "        logging.info(f'{name} = {param}')\n",
    "    \n",
    "    pubmed_pubtator = PubmedPubtatorDataset()\n",
    "    train_loader = DataLoader(pubmed_pubtator, batch_size=1, shuffle=True, num_workers=4)\n",
    "    valid_loader = DataLoader(pubmed_pubtator, batch_size=1, shuffle=True, num_workers=4)\n",
    "    \n",
    "    if args.init_checkpoint:\n",
    "        logging.info(f'Load checkpoint from {args.init_checkpoint}...')\n",
    "        checkpoint = torch.load(args.init_checkpoint)\n",
    "        \n",
    "    else:\n",
    "        logging.info('Start from scratch')\n",
    "    \n",
    "    if args.train:\n",
    "        train()\n",
    "        \n",
    "    if args.valid:\n",
    "        test()\n",
    "        \n",
    "    if args.test:\n",
    "        test_loader = DataLoader()\n",
    "        test()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, train_loader, val_loader, optimizer, loss_fn, scheduler=None):\n",
    "    '''Training loop'''\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(args.epoch):\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        start = time.time()\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            for sent in batch:  # Each batch is a doc (a list of sent)\n",
    "                \n",
    "                model.zero_grad()\n",
    "                \n",
    "                context, target = gen_lm_train_example(sent)\n",
    "                \n",
    "                start_ = time.time()\n",
    "                logits = model(context.type(tensor_type))\n",
    "                loss = loss_function(logits, target.type(tensor_type))\n",
    "                forward_time = time.time() - start_\n",
    "\n",
    "                start_ = time.time()\n",
    "                loss.backward()\n",
    "                backward_time = time.time() - start_\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "    \n",
    "    for (epoch + 1) % args.log_step == 0:\n",
    "        log()\n",
    "        \n",
    "    for (epoch + 1) % args.valid_step == 0:\n",
    "        model.eval()\n",
    "        valid_loss = valid()\n",
    "        log()\n",
    "        \n",
    "        if valid_loss < min_valid_loss:\n",
    "            save()\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_pubtator = PubmedPubtatorDataset()\n",
    "dataloader = DataLoader(data, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "# Train\n",
    "for EPOCH in range(NEPOCH):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        for sent in batch:\n",
    "            \n",
    "            model.zero_grad()\n",
    "            \n",
    "            context, target = gen_lm_train_example(sent)\n",
    "            \n",
    "            start_ = time.time()\n",
    "            logits = model(context.type(tensor_type))\n",
    "            loss = loss_function(logits, target.type(tensor_type))\n",
    "            forward_time = time.time() - start_\n",
    "\n",
    "            start_ = time.time()\n",
    "            loss.backward()\n",
    "            backward_time = time.time() - start_\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {EPOCH+1:4}:', \n",
    "          f'train_loss={train_loss:.4f},',\n",
    "          f'ppl={math.exp(train_loss/len(vocab)):.4f},',\n",
    "          f'time_per_epoch={(time.time()-start):.2f},',\n",
    "          f'time_per_iter={(time.time()-start)/i:.2f}')\n",
    "    \n",
    "    if (step + 1) % valid_step == 0:\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '/scratch/cheng.jial/dataset-nlp/pubmed_pubtator/pmid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubmedPubtatorDataset(Dataset):\n",
    "    '''PubMed abstract with PubTator NER.\n",
    "       Chemical/Disease/Gene transformed into MeSH IDs.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, root_dir=corpus, transform=[]):\n",
    "        self.root_dir = root_dir\n",
    "        self.pmid_list = os.listdir(root_dir)\n",
    "        self.pmid_list.sort()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pmid_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        pmid = self.pmid_list[idx]\n",
    "        doc_name = os.path.join(self.root_dir, pmid)\n",
    "        with open(doc_name, 'r') as f:\n",
    "            doc = f.readlines()\n",
    "        doc = [l.strip('\\n') for l in doc]\n",
    "        \n",
    "        for i in self.transform:\n",
    "            doc = self.transform(doc)\n",
    "            \n",
    "        return pmid, doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_pubtator = PubmedPubtatorDataset()\n",
    "dataloader = DataLoader(data, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Higgs-boson production in nucleus-nucleus collisions.', 'Cross-section calculations are presented for the production of intermediate-mass Higgs bosons produced in ultrarelativistic nucleus-nucleus collisions via two-photon fusion.', \"The calculations are performed in position space using Baur's method for folding together the DMESHD018980 spectra of the two colliding nuclei.\", 'It is found that two-photon fusion in nucleus-nucleus collisions is a plausible way of finding intermediate-mass Higgs bosons at the Superconducting Super Collider or the CERN Large Hadron Collider.']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    print(data[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [('Altered balance of functional brain networks in DMESHD012559.',), ('Activity in dorsal attention (DAN) and frontoparietal (FPN) functional brain networks is linked to allocation of attention to external stimuli, and activity in the default-mode network (G23336) is linked to allocation of attention to internal representations.',), ('Tasks requiring attention to external stimuli shift activity to the DAN/FPN and away from the G23336, and optimal task performance depends on balancing DAN/FPN against G23336 activity.',), ('The current functional magnetic resonance imaging (DMESHC564543) study assessed the balance of DAN/FPN and G23336 activity in 13 DMESHD012559 patients and 13 healthy controls while they were engaged in a task switching Stroop paradigm which demanded internally directed attention to task instructions.',), ('The typical pattern of reciprocity between the DAN/G23336 was observed for healthy controls but not for patients, suggesting a reduction in the internally focussed thought important for maintenance of instructions and strategies in DMESHD012559.',), ('The observed alteration in the balance between DAN/FPN and G23336 in patients may reflect a general mechanism underlying multiple forms of DMESHD003072, including global processing deficits such as DMESHD003072 and impaired context processing.',)]\n"
     ]
    }
   ],
   "source": [
    "for i_batch, batch in enumerate(dataloader):\n",
    "    print(i_batch, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    '''Tokenize all sentences in a doc'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tokenizer = spacy()\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        doc = [self.__tokenize__(sen) for sen in doc]\n",
    "        \n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    '''Convert all sentences in a docs to torch.Tensor'''\n",
    "    \n",
    "    def __init__(self, w2i):\n",
    "        self.w2i = w2i\n",
    "        \n",
    "    def __tokenize__(self, sentence):\n",
    "        tokens = [t.token for t in self.tokenizer(sentence)]\n",
    "        return tokens\n",
    "    \n",
    "    def __w2i__(self, word):\n",
    "        try:\n",
    "            return self.w2i[word]\n",
    "        except:\n",
    "            return self.w2i['<UNK>']\n",
    "    \n",
    "    def __totensor__(self, sent):\n",
    "        return torch.from_numpy(sent)\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        doc = [[self.__toidx__(sent) for w in sent] for sent in doc]\n",
    "        doc = [self.__totensor__(sent) for sent in doc]\n",
    "        \n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_transformers as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 3393306.21B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cm', '##esh', '##d', '##00', '##28', '##47']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"CMESHD002847\"\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Encode a text inputs\n",
    "text = \"CMESHD002847\"\n",
    "indexed_tokens = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ĠCM', 'ES', 'HD', '00', '28', '47']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5338, 373, 5395, 367, 19069, 5633, 5395, 367, 19069, 373, 257]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch CUDA 10.1",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
